#!/usr/bin/env python3
"""
æ–‡æ¡£å¤„ç†å™¨ - ä½¿ç”¨å·²å®‰è£…çš„åº“
åŠŸèƒ½ï¼šå°†é•¿æ–‡æ¡£åˆ†å‰²æˆé€‚åˆAIå¤„ç†çš„å°æ–‡æœ¬
æ ¸å¿ƒæ€æƒ³ï¼šå¤§æ–‡æ¡£â€”â€”>å°ç‰‡æ®µâ€”â€”>æ›´å¥½çš„æœç´¢æ•ˆæœ
"""

import os
from typing import List

class DocumentProcessor:
    def __init__(self, chunk_size: int = 300):
        self.chunk_size = chunk_size
    
    def load_documents(self, file_path: str) -> List[str]:
        """åŠ è½½æ–‡æ¡£å¹¶åˆ‡åˆ†æˆå—"""
        print("ğŸ“– æ­£åœ¨åŠ è½½æ–‡æ¡£...")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŒ‰ç©ºè¡Œåˆ†å‰²æ®µè½
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        
        chunks = []
        for para in paragraphs:
            # å¦‚æœæ®µè½å¤ªé•¿ï¼Œè¿›ä¸€æ­¥åˆ‡åˆ†
            if len(para) > self.chunk_size:
                words = para.split()
                current_chunk = []
                current_length = 0
                
                for word in words:
                    if current_length + len(word) + 1 > self.chunk_size:
                        chunks.append(' '.join(current_chunk))
                        current_chunk = [word]
                        current_length = len(word)
                    else:
                        current_chunk.append(word)
                        current_length += len(word) + 1
                
                if current_chunk:
                    chunks.append(' '.join(current_chunk))
            else:
                chunks.append(para)
        
        print(f"âœ… æˆåŠŸåˆ†å‰²å‡º {len(chunks)} ä¸ªæ–‡æœ¬å—")
        return chunks

# æµ‹è¯•è¿™ä¸ªæ¨¡å—
if __name__ == "__main__":
    processor = DocumentProcessor()
    chunks = processor.load_documents("data/return_policy.txt")
    
    print("\nå‰3ä¸ªæ–‡æœ¬å—é¢„è§ˆï¼š")
    for i, chunk in enumerate(chunks[:3]):
        print(f"å— {i+1}: {chunk[:80]}...")
