#!/usr/bin/env python3
"""
MLOpsç›‘æ§ç‰ˆæœåŠ¡ - ä¿®å¤ç‰ˆæœ¬
"""

import sys
import os
import time
import logging
from datetime import datetime
from typing import List, Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Request, Response
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn

# ========== æ·»åŠ ç›‘æ§ç›¸å…³å¯¼å…¥ ==========
from prometheus_client import (
    Counter, Histogram, Gauge, generate_latest, 
    CONTENT_TYPE_LATEST, REGISTRY, start_http_server
)
import psutil
import json

# ========== å…ˆå®šä¹‰æ‰€æœ‰æŒ‡æ ‡ ==========
# è¯·æ±‚ç›¸å…³æŒ‡æ ‡
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status_code']
)

REQUEST_LATENCY = Histogram(
    'http_request_duration_seconds',
    'HTTP request latency in seconds',
    ['method', 'endpoint']
)

# ä¸šåŠ¡ç›¸å…³æŒ‡æ ‡
RAG_QUERY_COUNT = Counter(
    'rag_queries_total',
    'Total RAG queries processed',
    ['query_type']
)

RAG_QUERY_LATENCY = Histogram(
    'rag_query_duration_seconds',
    'RAG query processing latency in seconds',
    ['query_type']
)

# ç³»ç»Ÿèµ„æºæŒ‡æ ‡
CPU_USAGE = Gauge('system_cpu_usage_percent', 'System CPU usage percentage')
MEMORY_USAGE = Gauge('system_memory_usage_percent', 'System memory usage percentage')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Number of active connections')

# ========== ç³»ç»ŸçŠ¶æ€ç›‘æ§ ==========
def get_system_metrics():
    """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
    CPU_USAGE.set(psutil.cpu_percent(interval=1))
    MEMORY_USAGE.set(psutil.virtual_memory().percent)
    
    # è·å–ç½‘ç»œè¿æ¥æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    connections = len(psutil.net_connections())
    ACTIVE_CONNECTIONS.set(connections)
    
    return {
        "cpu_percent": psutil.cpu_percent(interval=1),
        "memory_percent": psutil.virtual_memory().percent,
        "active_connections": connections,
        "timestamp": datetime.now().isoformat()
    }

# ========== æ•°æ®æ¨¡å‹ ==========
class Question(BaseModel):
    question: str
    top_k: Optional[int] = 3

class Answer(BaseModel):
    question: str
    answer: str
    relevant_documents: List[str]
    processing_time: float
    model_version: str = "1.0.0"

# ========== FastAPIåº”ç”¨ç”Ÿå‘½å‘¨æœŸ ==========
@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶
    print("ğŸš€ å¯åŠ¨æ™ºèƒ½å®¢æœç³»ç»Ÿï¼ˆMLOpsç›‘æ§ç‰ˆï¼‰...")
    
    # å¯åŠ¨PrometheusæŒ‡æ ‡æœåŠ¡å™¨ï¼ˆåœ¨8001ç«¯å£ï¼‰
    start_http_server(8001)
    print("ğŸ“Š PrometheusæŒ‡æ ‡æœåŠ¡å™¨å¯åŠ¨åœ¨ç«¯å£ 8001")
    
    yield  # åº”ç”¨è¿è¡Œä¸­
    
    # å…³é—­æ—¶
    print("ğŸ›‘ æ­£åœ¨å…³é—­æ™ºèƒ½å®¢æœç³»ç»Ÿ...")

# ========== åˆ›å»ºFastAPIåº”ç”¨ ==========
app = FastAPI(
    title="æ™ºèƒ½å®¢æœç³»ç»Ÿ - MLOpså¢å¼ºç‰ˆ",
    description="å¸¦æœ‰å®Œæ•´ç›‘æ§çš„RAGç³»ç»Ÿ",
    version="2.0.0",
    lifespan=lifespan
)

# ========== ä¸­é—´ä»¶ï¼šæ”¶é›†è¯·æ±‚æŒ‡æ ‡ï¼ˆç°åœ¨æ”¾åœ¨appå®šä¹‰ä¹‹åï¼‰ ==========
@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    start_time = time.time()
    method = request.method
    endpoint = request.url.path
    
    try:
        response = await call_next(request)
        
        # è®°å½•è¯·æ±‚æŒ‡æ ‡
        REQUEST_COUNT.labels(
            method=method,
            endpoint=endpoint,
            status_code=response.status_code
        ).inc()
        
        REQUEST_LATENCY.labels(
            method=method,
            endpoint=endpoint
        ).observe(time.time() - start_time)
        
        return response
        
    except Exception as e:
        REQUEST_COUNT.labels(
            method=method,
            endpoint=endpoint,
            status_code=500
        ).inc()
        raise e

# ========== APIç«¯ç‚¹ ==========
@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "æ™ºèƒ½å®¢æœç³»ç»Ÿ",
        "version": "2.0.0",
        "status": "running",
        "monitoring": {
            "metrics": "http://localhost:8000/metrics",
            "health": "http://localhost:8000/health",
            "docs": "http://localhost:8000/docs"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ˆMLOpsæ ‡å‡†ï¼‰"""
    system_status = get_system_metrics()
    
    # æ£€æŸ¥å…³é”®ç»„ä»¶
    checks = {
        "api_service": "healthy",
        "system_resources": "healthy" if system_status["cpu_percent"] < 90 else "warning",
        "database": "healthy",  # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æ•°æ®åº“æ£€æŸ¥
        "model_serving": "healthy"
    }
    
    overall_status = "healthy" if all(v == "healthy" for v in checks.values()) else "degraded"
    
    return {
        "status": overall_status,
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "checks": checks,
        "system": system_status
    }

@app.get("/metrics")
async def metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    # æ›´æ–°ç³»ç»ŸæŒ‡æ ‡
    get_system_metrics()
    
    # è¿”å›æ‰€æœ‰æŒ‡æ ‡
    return Response(
        generate_latest(REGISTRY),
        media_type=CONTENT_TYPE_LATEST
    )

@app.get("/system/status")
async def system_status():
    """è¯¦ç»†ç³»ç»ŸçŠ¶æ€"""
    return {
        "status": "running",
        "uptime": "TODO: è®¡ç®—è¿è¡Œæ—¶é—´",
        "resources": get_system_metrics(),
        "service_info": {
            "name": "æ™ºèƒ½å®¢æœç³»ç»Ÿ",
            "version": "2.0.0",
            "mlops_features": ["ç›‘æ§", "æŒ‡æ ‡", "å¥åº·æ£€æŸ¥", "æ—¥å¿—"],
            "rag_features": ["æ–‡æ¡£æ£€ç´¢", "å‘é‡æœç´¢", "æ™ºèƒ½é—®ç­”"]
        }
    }

@app.post("/ask", response_model=Answer)
async def ask(question: Question):
    """æ™ºèƒ½é—®ç­”ç«¯ç‚¹ï¼ˆå¸¦ç›‘æ§ï¼‰"""
    start_time = time.time()
    
    try:
        # è®°å½•æŸ¥è¯¢
        RAG_QUERY_COUNT.labels(query_type="general").inc()
        
        # è¿™é‡Œå¯ä»¥è°ƒç”¨ä½ çš„RAGé€»è¾‘
        # æš‚æ—¶ç”¨æ¨¡æ‹Ÿæ•°æ®
        answer = "è¿™æ˜¯æ¨¡æ‹Ÿå›ç­”ï¼šæ ¹æ®é€€è´§æ”¿ç­–ï¼Œå•†å“ç­¾æ”¶å7å¤©å†…å¯æ— ç†ç”±é€€è´§ï¼Œå•†å“å¿…é¡»ä¿æŒå®Œå¥½ï¼Œæ ‡ç­¾æœªæ‹†é™¤ã€‚"
        relevant_docs = [
            "å•†å“ç­¾æ”¶å7å¤©å†…å¯æ— ç†ç”±é€€è´§",
            "å•†å“å¿…é¡»ä¿æŒå®Œå¥½ï¼Œæ ‡ç­¾æœªæ‹†é™¤",
            "é€€è´§è¿è´¹ç”±ä¹°å®¶æ‰¿æ‹…"
        ]
        
        processing_time = time.time() - start_time
        
        # è®°å½•å»¶è¿Ÿ
        RAG_QUERY_LATENCY.labels(query_type="general").observe(processing_time)
        
        return Answer(
            question=question.question,
            answer=answer,
            relevant_documents=relevant_docs,
            processing_time=round(processing_time, 3)
        )
        
    except Exception as e:
        RAG_QUERY_COUNT.labels(query_type="error").inc()
        raise HTTPException(status_code=500, detail=str(e))

# ========== é”™è¯¯å¤„ç† ==========
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    return JSONResponse(
        status_code=500,
        content={
            "error": str(exc),
            "timestamp": datetime.now().isoformat(),
            "path": request.url.path
        }
    )

# ========== å¯åŠ¨åº”ç”¨ ==========
if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("=" * 60)
    print("ğŸŒ MLOpsæ™ºèƒ½å®¢æœç³»ç»Ÿ")
    print("ğŸ“ APIæœåŠ¡: http://localhost:8000")
    print("ğŸ“Š æŒ‡æ ‡åœ°å€: http://localhost:8000/metrics")
    print("ğŸ“š APIæ–‡æ¡£: http://localhost:8000/docs")
    print("ğŸ”¬ å†…éƒ¨æŒ‡æ ‡: http://localhost:8001")
    print("=" * 60)
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=True
    )
